

# Project

- λ¨λ“ ν”„λ μ„μ›ν¬ μ΄μ 
  - Hydra μ„¤μ • κ΄€λ¦¬
  - WandB(Weights & Biases)λ¥Ό ν†µν• μ‹¤ν— κ΄€λ¦¬ λ° μ‹κ°ν™” κΈ°λ¥
  - pytorch lighting
  - hugging face model manage

## Project_template 
- λ”¥λ¬λ‹ μ‹¤ν—μ„ μ„ν• λ¨λ“ν™”λ ν…ν”λ¦Ώ μ½”λ“ μ‘μ„±


## NLP Task Project Template κµ¬ν„
https://paperswithcode.com/dataset/dialogsum

- Dataset
    
    https://github.com/cylnlp/dialogsum/tree/main/DialogSum_Data
    
    - μ‹¤μ  λ€ν λ°μ΄ν„°μ…‹, μ„ λ°μ΄ν„° ν•κΈ€λ΅ λ²μ—­ν•΄ μ κ³µ
### template_nlp_sum (test_rouge)

### nlp

κ²€μ¦ μ™„λ£ β†’ κ°μ„  μ¤‘

- **DialogSum λ°μ΄ν„°μ…‹**
- **BART κΈ°λ° λ¨λΈ**
- ROUGE μ¤μ½”μ–΄ μ‚¬μ©
    - μƒμ„±λ μ”μ•½λ¬Έμ ν’μ§ ν‰κ°€

### summary


κ²€μ¦ μ™„λ£. 


**λ°μ΄ν„°μ…‹**

- **DialogSumΒ λ°μ΄ν„°μ…‹**
    - μ¶μ²: GitHub cylnlp/dialogsumΒ μ €μ¥μ†
    - κµ¬μ΅°: λ€ν™”(dialogue)μ™€ μ”μ•½(summary) μμΌλ΅ κµ¬μ„±
    - νμΌ:
        - train.json: ν•™μµ λ°μ΄ν„°
        - val.json: κ²€μ¦ λ°μ΄ν„°

**2. λ¨λΈ**

- **BART λ¨λΈ**
    - κΈ°λ³Έ λ¨λΈ: facebook/bart-large-cnn
    - ν¬κΈ°: μ•½ 400M νλΌλ―Έν„°
- **T5 λ¨λΈ**Β (λ€μ²΄ μµμ…)
    - κΈ°λ³Έ λ¨λΈ: t5-small
    - ν¬κΈ°: μ•½ 60M νλΌλ―Έν„°
    - μ„¤μ •:

**νμΈνλ‹ μ „λµ**:

- κ·Έλλ””μ–ΈνΈ μ²΄ν¬ν¬μΈν… μ‚¬μ©
- μ„ νƒμ  λ μ΄μ–΄ λ™κ²°
- μ„λ² λ”© λ μ΄μ–΄ λ™κ²° μµμ…

**4. ν‰κ°€ λ©”νΈλ¦­**

- **ROUGE μ μ**

<aside>
π’΅

</aside>

- ν•™μµμ— λ”°λ¥Έ metric κ°μ„  ν™•μΈ

Evaluating model...Evaluating: 100%|β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–| 10/10 [00:05<00:00,Β  1.99it/s]Validation ROUGE scores: {'rouge1': 0.3878867728969686, 'rouge2': 0.1951162475308493, 'rougeL': 0.3183383168823225}

Validation ROUGE scores: {'rouge1': 0.41737868855929205, 'rouge2': 0.2105218297398614, 'rougeL': 0.3501939765357674}
# Study

https://github.com/kafkapple/project_template
## Quantization & dtype Precision

### Mixed Precision **νΌν•© μ •λ°€λ„λ€?**

- νΌν•© μ •λ°€λ„λ” **λ‹¨μΌ λ¨λΈμ—μ„ μ„λ΅ λ‹¤λ¥Έ λ°μ΄ν„° μ ν•μ μ •λ°€λ„**λ¥Ό μ‚¬μ©ν•λ” κΈ°λ²•
    - μ£Όλ΅ **float32**μ™€ **float16**(λ°μ •λ°€λ„) λ‘ κ°€μ§€λ¥Ό νΌν•©ν•μ—¬ μ‚¬μ©
- **float32**:
    - 32λΉ„νΈ λ‹¨μ •λ°€λ„. 
    - κΈ°μ΅΄ ν•™μµμ—μ„ μ£Όλ΅ μ‚¬μ©λ¨. 
    - μ—°μ‚°μ€ μ •ν™•ν•μ§€λ§ λ©”λ¨λ¦¬μ™€ μ—°μ‚° λΉ„μ©μ΄ νΌ.
- **float16**:
    - 16λΉ„νΈ λ°μ •λ°€λ„. 
    - λ©”λ¨λ¦¬ μ‚¬μ©λ‰μ΄ μ λ°μ΄μ§€λ§, μ¤μ°¨λ‚ μ–Έλ”ν”λ΅μ°κ°€ λ°μƒ

### Torch `torch_dtype` μ£Όμ” μµμ… μ„¤λ… λ° μ‚¬μ©λ²•

1. **`torch.float32` (κΈ°λ³Έκ°’)**:
    - **νΉμ§•**:
        - 32λΉ„νΈ λ¶€λ™μ†μμ  ν•μ‹.
        - λ†’μ€ μ •ν™•λ„ μ κ³µ.
        - λ©”λ¨λ¦¬ μ‚¬μ©λ‰μ΄ νΌ.
    - **μ‚¬μ© μ**:
        
        ```python
        
        model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype=torch.float32  # λ†’μ€ μ •ν™•λ„λ¥Ό μ”κµ¬ν•  λ•
        )
        
        ```
        
2. **`torch.float16`**:
    - **νΉμ§•**:
        - 16λΉ„νΈ λ¶€λ™μ†μμ  ν•μ‹.
        - λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μ•½ 50% κ°μ†.
        - μ•½κ°„μ μ •ν™•λ„ μ†μ‹¤ κ°€λ¥.
        - GPUμ—μ„ μ—°μ‚° μ†λ„ ν–¥μƒ.
    - **κ¶μ¥ μ‹λ‚λ¦¬μ¤**:
        - λ€ν• λ¨λΈ (μ: LLaMA, GPT λ“±)μ—μ„ GPU λ©”λ¨λ¦¬ μ μ•½μ΄ ν•„μ”ν•  λ•.
    - **μ‚¬μ© μ**:
        
        ```python
        
        model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype=torch.float16,  # GPU λ©”λ¨λ¦¬ μ μ•½
            device_map="auto",         # μλ™ μ¥μΉ ν• λ‹Ή
            offload_folder="offload"   # ν•„μ”μ‹ λ””μ¤ν¬λ΅ μ¤ν”„λ΅λ“
        )
        
        ```
        
3. **`torch.bfloat16`**:
    - **νΉμ§•**:
        - Brain Floating Point ν•μ‹ (Google TPUμ—μ„ μ²μ λ„μ…).
        - `torch.float16`λ³΄λ‹¤ λ” μ•μ •μ μΈ μμΉ μ—°μ‚° μ κ³µ.
        - NVIDIA Ampere GPU (μ: A100)μ—μ„ μµμ ν™”.
    - **κ¶μ¥ μ‹λ‚λ¦¬μ¤**:
        - λ€ν• λ¨λΈμ—μ„ μμΉ μ•μ •μ„±μ΄ μ¤‘μ”ν• κ²½μ°.
    - **μ‚¬μ© μ**:
        
        ```python
        
        model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype=torch.bfloat16,  # μ•μ •μ μΈ μ—°μ‚°
            device_map="auto"
        )
        
        ```
        

---

### **Quantization 8λΉ„νΈ μ–‘μν™”**

- **νΉμ§•**:
    - 8λΉ„νΈλ΅ λ¨λΈ κ°€μ¤‘μΉλ¥Ό μ–‘μν™”ν•μ—¬ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ ν¬κ² μ κ°.
    - μ μ€ GPU λ©”λ¨λ¦¬λ΅ λ€ν• λ¨λΈ μ‹¤ν–‰ κ°€λ¥.
    - μ•½κ°„μ μ„±λ¥ μ†μ‹¤ λ°μƒ κ°€λ¥.
- **μ‚¬μ© μ**:
    
    ```python
    
    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        load_in_8bit=True,       # 8λΉ„νΈ μ–‘μν™”
        device_map="auto"
    )
    
    ```
    

---

### **LLaMAμ™€ κ°™μ€ λ€ν• λ¨λΈ κ¶μ¥ μ„¤μ •**

```python

model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16,  # GPU λ©”λ¨λ¦¬ μ μ•½
    device_map="auto",         # μλ™ μ¥μΉ ν• λ‹Ή
    offload_folder="offload"   # λ””μ¤ν¬λ΅ μ¤ν”„λ΅λ“ κ°€λ¥
)

```

- **μ¶”κ°€ μµμ…**:
    - **`device_map="auto"`**: μ—¬λ¬ GPU λλ” CPU ν™κ²½μ—μ„ μλ™μΌλ΅ μ¥μΉλ¥Ό μ„¤μ •.
    - **`offload_folder="offload"`**: GPU λ©”λ¨λ¦¬ λ¶€μ΅± μ‹ λ””μ¤ν¬λ΅ λ°μ΄ν„°λ¥Ό μ¤ν”„λ΅λ“.

## Powershell - conda μ΄μ

- conda μ„¤μΉ μ„μΉ ν™•μΈ

- **μƒ ν”„λ΅ν•„ νμΌ κ²½λ΅ μ„¤μ •**:
    - `$PROFILE` κ°’μ„ μ¬μ •μ.
    - PowerShell μ„Έμ…μ—μ„ μ•„λ λ…λ Ήμ„ μ‹¤ν–‰
    
    ```powershell
    
    $PROFILE = "D:\MyPowerShellProfiles\Microsoft.PowerShell_profile.ps1
    ```
    
- **μƒ ν”„λ΅ν•„ νμΌ μ‘μ„± λ° λ‚΄μ© μ¶”κ°€**:
μƒ κ²½λ΅μ— νμΌμ„ μƒμ„±ν•κ³ , μ•„λ μ½”λ“λ¥Ό μ¶”κ°€
    
    ```powershell
    
    New-Item -ItemType File -Path $PROFILE -Force
    notepad $PROFILE
    ```
    
    **μ¶”κ°€ λ‚΄μ©**:
    
    ```powershell
    
    & "C:\Users\joon\miniconda3\Scripts\conda.exe" shell.powershell hook | Out-String | Invoke-Expression
    ```
    
- **PowerShell μ‹¤ν–‰ μ‹ μƒ κ²½λ΅ μ°Έμ΅°**:
PowerShellμ„ μ¬μ‹μ‘ν•λ©΄ μƒ μ„μΉμ ν”„λ΅ν•„ νμΌμ΄ μ μ©