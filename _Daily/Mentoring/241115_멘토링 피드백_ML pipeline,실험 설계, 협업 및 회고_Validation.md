

### why? 팀/개인 별 목표 잘 설정하고 시작

- **이유**: 팀별 목표를 명확히 설정하고, 데이터의 목적과 맥락에 맞는 검증 집합 구성 필요.
- 현업에서는 **무엇을 했는지, 어떤 인사이트를 얻었는지**를 명확히 전달하는 것이 중요.
    - 실험 결과 자체 만큼, 발표 구성 등

### **1. Validation 데이터 중요성**

- **Random하게 분할하지 말 것**
    - cross validation 이 꼭 더 좋은 것은 아님.
    - Random 분할 대신, 데이터 특성과 목적에 맞게 Validation Set 구성.
    - Validation 결과를 통해 모델 성능을 유추하는 것이 중요.

→ train, val metric 결과의 gap 으로 유추 가능?

---

### **2. 정형 vs 비정형 데이터 접근**

- 정형 데이터 접근 방식에서 학습한 내용을 비정형 데이터(영상, 사진, 음성 등)에 적용할 수 있을지 질문.
    - **비정형 데이터**는 용량이 크므로, 초기 단계에서 **down-sampling 기준**과 **추출 지표** 설정이 중요.
    - Tabular dataset 생성 후 EDA를 시작하는 것이 적합할 가능성 높음.
    - EDA 과정에서 어떤 지표를 사용할지 명확히 정의.

---

### **3. ML 분석 루틴과 실험 전략**
- **이론적 루틴**:
    - Data Preparation → Feature Engineering → Modeling.
    - 하지만 실전에서는 선형적이지 않고, 반복적이고 역동적임.
    -  초기 단계의 데이터 구성/검증이 중요.
- **데이터 중심 접근**:
    - 데이터셋과 Validation Set 구성이 제대로 되지 않으면, 후속 작업의 성과가 미미.
    - 모델링에 집중하기 전에 데이터의 구조와 특성을 충분히 이해.
    - 데이터를 소홀히 하면 후속 작업에서 성과가 거의 없거나 우연에 의존.

- **개선 목표**:
    - 실험 루틴:
        - Filter/Wrapper/Embedding Method로 주요 변수 선택.
        - EDA를 통해 결측치, 이상치 처리 후 Feature Engineering 반복.
    - 왕도는 없으며, 개인마다 경험과 스타일을 통해 적합한 루틴을 만들어감.

### 4. **실험 설계와 의사결정**

- **데이터와 통계 지표**:
    - 통계 지표는 필수적이나 맹신하지 말고, 시각화와 정성적 분석을 병행.
    - 도메인 지식과 통계적 정보가 조화롭게 활용되어야 함.
- **실험 설계**:
    - 가능한 **한 가지 요소씩** 변경하며 실험.
    - 프로젝트 목적에 맞게 **우선순위 조율**과 **선택과 집중**.
-  **EDA**:
     - **결측치, 이상치 처리 방식 탐색**.
     - 데이터의 정성적/정량적 분석.
- **결측치 처리**:
   - 단순 평균보다 Random Forest 등 모델 기반 처리 시도.
   - 이상치는 실험과 모델 성능 분석에 기반해 판단.

- **Modeling**:
  - Baseline 모델(RandomForest)로 시작, 이후 점진적 개선(XGBoost 등).
- **Feature Selection**:
    - **Filter Method**:
        - Variance 기준: 0.1 이하 제거.
        - Correlation 기준: 0.9 이상 제거.
    - **Wrapper Method**:
        - Sequential Feature Selection(SFS).
        - Recursive Feature Elimination(RFE).
    -  **Feature Engineering**:
        - Encoding 방식 비교(label encoding, one-hot, frequency encoding).
        - Null 값 처리: 평균, 모델 기반 보완(Random Forest 등).


---

### **4. 주요 피드백**

- **통계적 접근과 정성적 접근**의 균형:
    - 통계 지표에 지나치게 의존하지 말고, 데이터 특성을 느끼고 파악.
    - 논문 읽기와 사례 학습으로 인사이트 확대.
- **사이클링**: 실험과 분석을 반복하며 경험 축적.
    - 실험마다 기록하고 회고 진행 필요.
- **Validation & Test Set 구성**:
    - 모델 성능 판단은 Validation 결과에 의존.
    - 리더보드 제출에 과도하게 몰입하지 말 것.

---

### **5. 실험 전략 개선**

- **실험 속도보다 체계적 접근 중요**:
    - 지나친 자율성이 오히려 팀의 방향성을 저하시킬 수 있음.
    - **논의 후 실험**을 진행하고, 실험 요소를 한 번에 다 바꾸지 말 것.
- **회고와 기록의 부족**:
    - 실험 후 회고를 통해 무엇을 배웠는지 정리 부족.
    - 점수에 치중하기보다 프로세스 개선에 집중.
---
### 6. **협업과 회고**

- **팀 내 협업**:
    - 자율성이 장점이자 단점으로 작용:
        - 각자 빠르게 진행했으나, 논의가 부족해 체계적 접근 부족.
    - "즐기는 데" 과몰입하여 충분한 고찰과 논의 부족.
- **실험 결과 분석**:
    - 다양한 요소를 한 번에 실험해 후속 개선과 분석이 어려움.
    - 실험 결과로 모델 성능은 개선되었으나, 분석 가능한 범위 내에서의 실험 설계 부족.
- **회고의 필요성**:
    - 프로젝트 종료 후 체계적이고 심층적인 회고를 진행하지 못한 점 반성.
---

### **7. 주요 교훈**

- **데이터와 피처에 대한 고민**:
    - 데이터의 질과 구성에 대한 고찰이 모델 성능을 좌우.
    - 예: Cross-validation vs Hold-out, Target y log transform 실패 경험.
- **기본에 충실한 실험 루틴**:
    - 서두르지 않고, 데이터를 이해하며 논의 기반의 실험.
- **결과보다는 과정**:
    - 점수보다는 충분한 고찰과 체계적 접근을 통해 데이터와 모델의 본질을 파악.


---

### **Q1: 비정형 데이터(영상, 사진, 음성)에서도 정형 데이터와 유사한 접근법을 사용할 수 있을까?**

비정형 데이터는 크기와 복잡성 때문에 추가적인 전략이 필요

1. **Down-Sampling 및 Feature 추출**
    - **기준**: 분석 목표와 도메인 지식에 따라 결정합니다.예: 영상의 경우 프레임 레이트를 낮추거나 특정 시간 간격으로 키 프레임을 추출
    - **지표**:
        - 영상: 모션 벡터, 프레임 밝기, 색상 분포.
        - 음성: MFCC, 스펙트로그램 패턴.
        - 사진: SIFT, HOG, CNN 임베딩.
2. **1차 Tabular Dataset 생성**
    - 비정형 데이터를 정형 데이터로 변환해, 각 샘플의 주요 지표(feature)로 구성된 테이블.이 단계에서 기존의 정형 데이터 EDA 접근 방식을 활용
3. **EDA 및 모델링 통합**
    - 데이터의 시각화와 통계적 분석을 통해 이상치와 패턴을 탐색
    - 초기 간단한 베이스라인 모델로 중요 지표를 검증

---

### **Q2: ML 분석 로직에 왕도가 있는가?**

ML 파이프라인은 이론적으로 **Data Prep → Feature Engineering → Modeling** 순서지만, 실제로는 비선형


1. **초기 설정**
    - **데이터셋 구성 검토**: Train/Test 분리 및 Validation 전략 세부 검토.
    - **데이터 샘플링**: 편향되지 않도록 설계.
2. **초기 변수 선택**
    - **Filter Method**: 통계적 기준(Correlation, ANOVA 등)으로 변수 걸러내기.
    - **Wrapper Method**: Feature Importance 상위 n개 선택.
    - **Embedding Method**: 학습된 임베딩 사용(CNN, Word2Vec 등).
3. **EDA 및 Feature Engineering**
    - **결측치 처리**: 단순 평균 대신, 예측 모델(Random Forest 등)로 보완.
    - **이상치 제거**: 통계적 분석 및 도메인 지식 기반.
    - **Feature Engineering**: 스케일링, 변환(log, sqrt 등), 조합 생성.
4. **모델링과 검증**
    - 초기 베이스라인 모델에서 시작, 성능 기반 점진적 개선.
    - **Cross-Validation 사용**: Hold-out보다 데이터 활용도가 높음.
5. **체계적 실험**
    - 각 실험에서 한 가지 변수만 변경하여 영향을 추적.
    - 결과 분석 후 다음 단계 결정.

---

### **Q3: 실험 루틴과 회고에 대한 교훈**

1. **구체적 루틴 정리**
    - 루틴을 명확히 정의하고, 실험 결과를 체계적으로 기록.
    - 논의 후 실행, 그리고 후속 조치를 설계.
2. **초점 맞추기**
    - 데이터셋과 Feature에 대한 깊은 관심이 모델링보다 우선.
    - 스코어에 과몰입하지 말고 데이터 자체를 이해하는 데 시간 투자.
3. **논의와 피드백 강화**
    - 자율성이 필요하지만, 논의 부족은 팀 성과 저하로 이어질 수 있음.
    - 속도보다 신중한 논의와 체계적 실험이 중요.
4. **실험의 복잡성 관리**
    - 너무 많은 변수를 한 번에 실험하면, 분석과 후속 개선이 어려움.
    - 단일 변수 실험으로 영향력을 평가.
5. **회고와 기록**
    - 충분히 회고하고, 실험 과정과 결과를 정리해 다음 사이클에 반영.

---

### **추가 고민**

1. **Cross-Validation**
    - Cross-Validation이 Hold-out 대비 더 나은 결과를 주지 못한 이유를 분석:데이터 분포, 샘플 수 불균형, 또는 Validation 전략에 문제가 있을 수 있음.
2. **Target 변환의 효과**
    - Log 변환 후 성능 저하: 변환이 데이터 분포와 모델링 과정에 적합했는지 확인.
3. **데이터 중심의 접근 강화**
    - 데이터 이해가 부족하면 모델링 단계에서의 개선은 한계가 있음.
  