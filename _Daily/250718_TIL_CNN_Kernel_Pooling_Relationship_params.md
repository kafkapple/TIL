# 📄 CNN_Kernel_Pooling_Relationship

CNN에서 여러 커널과 풀링은 계층적 특징 추출과 효율적인 정보 압축을 통해 이미지 인식 성능을 최적화

### 1. CNN의 계층적 특징 추출

#### 1.1 다중 커널의 역할

- **다양한 특징 감지**: 한 레이어에서 여러 커널을 사용하여 모서리, 점, 곡선 등 다양한 형태의 특징 추출.

- **Feature Map 생성**: 각 커널은 독립적인 Feature Map을 생성하여 입력 이미지의 다각적인 표현 획득.

- **표현력 증대**: 커널 수가 많을수록 모델의 표현력이 증가하여 복잡한 패턴 학습 가능.

#### 1.2 다층 커널 구조의 의미

- **계층적 특징 학습**: 얕은 층은 단순 특징, 깊은 층은 복잡하고 추상적인 특징 학습.

- **정보의 점진적 추상화**: Conv → Pooling 반복 구조를 통해 이미지 특징을 점진적으로 추출 및 추상화.

- **일반적인 구조**: Conv2D → ReLU → Pooling 반복으로 구성.

### 2. Pooling의 기능 및 연결 방식

#### 2.1 Pooling의 역할

- **공간 크기 축소**: Feature Map의 공간적 차원(가로, 세로)을 줄여 연산량 감소.

- **위치 변화 강건성**: 특징의 미세한 위치 변화에 덜 민감하게 만들어 모델의 일반화 성능 향상.

- **채널 독립적 적용**: 각 Feature Map(채널)에 독립적으로 적용되며 채널 수는 유지.

#### 2.2 채널 연결 및 Flatten

- **다음 레이어 입력**: 이전 레이어의 출력 Feature Map(채널) 전체가 다음 Conv 레이어의 입력 채널로 사용.

- **FC 레이어 연결**: CNN 후단에서 공간 정보를 Flatten하여 1차원 벡터로 변환 후 Fully Connected 레이어에 입력.

- **채널 수 증가 경향**: 일반적으로 딥러닝 모델이 깊어질수록 채널(필터) 수를 늘려 복잡한 특징을 포착.

### 3. CNN 하이퍼파라미터 튜닝

#### 3.1 Conv2D 필터 개수 (dim_1, dim_2)

- **모델 표현력**: 필터 개수는 모델의 표현력과 복잡성에 직접적인 영향.

- **일반적 값**: 초기 레이어 16-64, 후반 레이어 64-128 등 2배수로 증가시키는 경향.

- **데이터셋 난이도**: 단순 이미지(MNIST)는 적은 필터, 컬러 이미지(CIFAR)는 많은 필터 권장.

#### 3.2 드롭아웃 비율 (dropout_rate)

- **과적합 방지**: 학습 중 뉴런을 임의로 비활성화하여 과적합을 방지하는 정규화 기법.

- **일반적 값**: 0.2 ~ 0.5 (20% ~ 50%).

- **활용 예시**: 과적합 시 비율 증가, 데이터가 적거나 간단할 때 낮은 비율 사용.

#### 3.3 배치 크기 (batch_size)

- **학습 효율성/안정성**: 한 번의 가중치 업데이트에 사용되는 샘플 수로, 학습 효율과 안정성에 영향.

- **일반적 값**: 32, 64, 128, 256 (대부분 2의 배수).

- **활용 예시**: 소규모 데이터/메모리 제한 시 16-32, GPU 여유 시 64-256.