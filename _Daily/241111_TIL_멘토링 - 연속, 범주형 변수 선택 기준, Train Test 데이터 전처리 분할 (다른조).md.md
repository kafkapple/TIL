# 멘토링 - 연속, 범주형 변수 선택 기준, Train Test 데이터 전처리 분할 (다른조)

### 요약: RMSE 개선, 전처리 및 모델 최적화에 대한 멘토링 정리

---

### 1. **RMSE 개선을 위한 주요 단계**

- **현재 상태**:

- 연속형 변수: OLS Regression과 VIF를 통해 다중공선성 제거.

- R-squared = 0.824, Cond.No = 29.

- 범주형 변수: Cramer’s V로 상관성이 높은 변수 제거(5개 이상).

- **추천 방법**:

1. **전처리 개선**:

- 새로운 유의미한 변수 생성:

- 연속형 변수 간 상호작용 변수 또는 조합 변수 추가.

- 예: 변수 A × B 또는 A + B 형태.

- 이상치 제거:

- RMSE는 이상치에 민감하므로 제거를 통해 성능 향상 가능.

- 예: `[1, 2, 3, 4, 123123]` → `[1, 2, 3, 4]`.

2. **모델 최적화**:

- **Baseline(RandomForest)**:

- 하이퍼파라미터 튜닝:

- `max_depth`, `min_samples_split`, `n_estimators` 최적화.

- Boosting 모델 활용:

- XGBoost, LightGBM 등 Boosting 모델은 복잡한 데이터에서 더 나은 성능을 기대할 수 있음.

---

### 2. **Train/Test 데이터 전처리 방식**

- **두 가지 접근**:

1. Train/Test를 합쳐서 전처리:

- 장점: 전처리의 일관성 보장.

- 단점: 데이터 누수 위험 증가.

2. Train/Test를 분리하여 전처리:

- 장점: 데이터 누수를 방지.

- 단점: 전처리가 복잡하고 일관성 유지가 어려울 수 있음.

- **멘토링 조언**:

- 데이터셋마다 결과가 다르므로 직접 실험해볼 것을 추천.

- 실험 경험은 실질적인 역량 강화에 필수적이며, 추후 문제 해결 능력을 높임.

---

### 3. **결론**

- 변수 제거가 지나치면 성능 저하 가능성을 인식하며, 새로운 변수 생성이나 이상치 제거를 통해 성능 개선을 시도.

- 모델 최적화 및 다양한 모델 시도(RandomForest → Boosting)로 성능 향상 가능.

- 전처리 방식은 데이터셋 특성에 따라 실험적으로 결정하며, 개발자로서의 경험 축적이 중요.