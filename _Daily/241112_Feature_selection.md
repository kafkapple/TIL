## Feature Selection:
### 1. **변수 선택의 필요성**
- **문제점**:
    - 변수가 많을수록 높은 비용 발생.
    - 과적합 우려 증가.
    - 해석 가능성 저하.
- **목표**:
    - 핵심 변수만 선택하여 모델 성능 향상 및 해석 가능성 증대.
---
### 2. **변수 선택 방법 분류**
변수 선택 방법은 **기준**에 따라 세 가지로 나뉨:
1. **Filter Methods**:
    - 변수 간 **통계적 관계** 기반으로 선택.
    - **특징**:
        - 모델 학습에 영향을 미치지 않음.
        - 빠른 속도와 단순성.
    - **예시**:
        - **분산 낮은 변수 제거**:
            - Variance Threshold: 분산이 특정 기준보다 낮은 변수 제거.
        - **상관계수 높은 변수 제거**:
            - Correlation Threshold: 상관계수가 높은 변수 중 하나 제거.
        - **카이제곱 기반 선택**:
            - 카이제곱 독립검정(Chi-Square Test):
                - 두 범주형 변수 간 관계를 통계적으로 검증.
                - **절차**:
                    1. 카이제곱 통계량 계산.
                    2. p-value가 유의 수준 이하라면 귀무가설 기각.
                    3. 유의미한 변수 선택.
2. **Wrapper Methods**:
    - **모델 성능**과 검증 결과 기반으로 선택.
    - **특징**:
        - 변수 간 상호작용 고려.
        - 단점: 속도가 느림.
    - **예시**:
        - **순차적 특성 선택**:
            - Sequential Feature Selection(SFS):
                1. 변수를 하나씩 추가하며 성능 평가.
                2. 성능이 더 이상 개선되지 않을 때까지 반복.
        - **재귀적 특성 제거**:
            - Recursive Feature Elimination(RFE):
                1. 모델 성능에 적게 기여하는 변수를 하나씩 제거.
                2. 성능이 최적화될 때까지 반복.
3. **Embedded Methods**:
    - **모델 훈련 과정에서 중요도를 계산**하여 선택.
    - **특징**:
        - Feature Importance와 Regularization 기법 사용.
    - **예시**:
        - **Tree-Based Feature Importance**:
            - 트리 모델에서 변수 중요도를 Gini 계수, Entropy 기반으로 계산.
            - 노드 분할에 기여한 변수가 중요도가 높음.
        - **Regularization 기반**:
            - 불필요한 변수의 가중치를 0 또는 0에 가깝게 조정하여 제거.
            - **Lasso(L1)**: 계수를 정확히 0으로 만들어 변수 제거.
            - **Ridge(L2)**: 계수를 0에 가깝게 조정.
---
### 3. **추가 기법**
1. **Target Permutation**:
    - 변수와 타겟 간 관계를 평가하기 위해 타겟 값을 무작위로 섞고 변수 중요도를 측정.
    - 원래 타겟과의 중요도 차이를 기반으로 유의미한 변수를 선택.
2. **Adversarial Validation**:
    - Train과 Validation 데이터셋의 분포가 다를 경우 모델 성능에 악영향.
    - Adversarial 모델로 train/val 데이터 구별 여부를 평가하여 데이터 분포 차이를 줄이는 데 활용.
---
### 4. **결론**
- 변수 선택은 단순히 변수 수를 줄이는 것을 넘어, 모델 성능 향상과 해석 가능성 확보를 목표로 함.
- **Filter**, **Wrapper**, **Embedded** 방법론은 각각의 장단점과 상황에 맞게 적절히 선택.
- 고급 기법(Target Permutation, Adversarial Validation)을 활용하여 데이터셋 품질과 신뢰도 향상 가능.